# GSF IR KTS â€” Architecture Plan

## 1. System Overview

GSF IR KTS is a **multi-agent system** integrated with GitHub Copilot Chat via a VS Code Extension. The system has 10 specialized agents (no separate conductor â€” Copilot handles intent classification). The system ingests heterogeneous documents from network file shares, extracts text and images, builds a searchable knowledge base, and serves both onboarding and operational support use cases through Copilot Chat.

### 1.1 High-Level Architecture

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         User Interface        â”‚
                    â”‚   (Streamlit UI  +  CLI)      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚       Conductor Agent          â”‚
                    â”‚  (Request Classification &     â”‚
                    â”‚   Pipeline Orchestration)      â”‚
                    â””â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”˜
                       â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                 â”‚   â”‚   â”‚   â”‚   â”‚                  â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â–¼â”  â”‚  â”Œâ–¼â”€â”€â”€â–¼â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚ Crawler â”‚      â”‚Ingestionâ”‚  â”‚  â”‚  Graph   â”‚       â”‚Freshnessâ”‚
    â”‚  Agent  â”‚      â”‚ Agent   â”‚  â”‚  â”‚ Builder  â”‚       â”‚  Agent  â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                â”‚       â”‚       â”‚
         â”‚           â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
         â”‚           â”‚ Vision  â”‚  â”‚  â”‚   Q&A    â”‚
         â”‚           â”‚  Agent  â”‚  â”‚  â”‚  Agent   â”‚
         â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                        â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Taxonomy   â”‚         â”‚   Version    â”‚
    â”‚    Agent     â”‚         â”‚    Agent     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚Training Path â”‚  â”‚Change Impact â”‚
              â”‚    Agent     â”‚  â”‚    Agent     â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Data Flow â€” Ingestion Pipeline

```
Network File Share(s)
    â”‚
    â–¼
[Crawler Agent] â”€â”€â”€ scans paths, computes hashes â”€â”€â”€â–¶ manifest.json
    â”‚                                                    â”‚
    â”‚  new/changed files detected                        â”‚ known files
    â–¼                                                    â–¼
[Ingestion Agent] â”€â”€â”€ extracts text + images            (skip)
    â”‚
    â”œâ”€â”€ text â”€â”€â–¶ Markdown (.md) â”€â”€â–¶ [Taxonomy Agent] â”€â”€â–¶ tagged metadata
    â”‚                                                         â”‚
    â”‚                                                    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                    â”‚ Vector Store â”‚
    â”‚                                                    â”‚  (ChromaDB)  â”‚
    â”‚                                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â””â”€â”€ images â”€â”€â–¶ assets/{doc_id}/img_NNN.png
                        â”‚
                   pending_descriptions.json
                        â”‚
                   [Vision Agent] â—„â”€â”€ Maintenance Engineer
                        â”‚               (GitHub Models)
                        â–¼
                   descriptions.json â”€â”€â–¶ Vector Store
                                    â”€â”€â–¶ [Graph Builder] â”€â”€â–¶ Knowledge Graph
```

### 1.3 Data Flow â€” Query Pipeline

```
User Question in Copilot Chat
    â”‚
    â–¼
[GitHub Copilot] â”€â”€â”€ classifies intent, calls @kts tool
    â”‚
    â”œâ”€â”€ QUESTION â”€â”€â–¶ [Retrieval Service]
    â”‚                   â”‚
    â”‚                   â”œâ”€â”€ Vector search (text + image descriptions)
    â”‚                   â”œâ”€â”€ Graph traversal (related docs, tools, processes)
    â”‚                   â”œâ”€â”€ Re-rank results by relevance
    â”‚                   â””â”€â”€ Return context + citations to Copilot
    â”‚                       â”‚
    â”‚                       â–¼
    â”‚                   [Copilot's LLM generates answer using context]
    â”‚
    â”œâ”€â”€ TRAINING â”€â”€â–¶ [Training Path Agent]
    â”‚                   â”‚
    â”‚                   â”œâ”€â”€ Graph query: find topic-related documents
    â”‚                   â”œâ”€â”€ Follow prerequisite edges
    â”‚                   â”œâ”€â”€ Order by difficulty / dependency
    â”‚                   â””â”€â”€ Return structured learning path
    â”‚
    â”œâ”€â”€ IMPACT â”€â”€â–¶ [Change Impact Agent]
    â”‚                   â”‚
    â”‚                   â”œâ”€â”€ Graph query: tool/process â†’ all dependent docs
    â”‚                   â”œâ”€â”€ Check document freshness
    â”‚                   â””â”€â”€ Return impact report
    â”‚
    â””â”€â”€ AUDIT â”€â”€â–¶ [Freshness Agent]
                    â”‚
                    â”œâ”€â”€ Scan all documents for staleness indicators
                    â”œâ”€â”€ Check for broken image references
                    â”œâ”€â”€ Cross-reference with latest tool versions
                    â””â”€â”€ Return freshness report
```

---

## 2. Component Architecture

### 2.1 Agent Framework (Reused from ABS)

All agents inherit from `AgentBase` and return `AgentResult`:

```python
@dataclass
class AgentResult:
    success: bool
    data: dict
    confidence: float        # 0.0 - 1.0
    reasoning: str           # Explanation of how result was derived
    citations: list[dict]    # Source documents referenced
    escalation: dict | None  # If confidence < threshold

class AgentBase(ABC):
    agent_name: str
    agent_version: str

    @abstractmethod
    def execute(self, request: dict) -> AgentResult:
        ...

    def quality_check(self, result: AgentResult) -> AgentResult:
        """Standard quality gate â€” reused from ABS playbook."""
        ...
```

### 2.2 Storage Layer

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Storage Layer                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Vector Store   â”‚    Knowledge Graph            â”‚
â”‚  (ChromaDB)     â”‚    (NetworkX â†’ JSON)          â”‚
â”‚                 â”‚                               â”‚
â”‚  Collections:   â”‚    Node Types:                â”‚
â”‚  - text_chunks  â”‚    - Tool, Process, Document, â”‚
â”‚  - image_descs  â”‚      DocVersion, Image,       â”‚
â”‚                 â”‚      Person, Team, DocType,    â”‚
â”‚  Metadata per   â”‚      Topic                    â”‚
â”‚  chunk:         â”‚                               â”‚
â”‚  - doc_id       â”‚    Edge Types:                â”‚
â”‚  - doc_type     â”‚    - uses, documented_in,     â”‚
â”‚  - source_path  â”‚      has_version, contains,   â”‚
â”‚  - version      â”‚      mentions, authored_by,   â”‚
â”‚  - chunk_index  â”‚      member_of, has_release,  â”‚
â”‚  - is_image_descâ”‚      changes, prerequisite,   â”‚
â”‚  - image_path   â”‚      tagged_as, covers_topic, â”‚
â”‚                 â”‚      supersedes               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                  File System                     â”‚
â”‚  knowledge_base/                                â”‚
â”‚  â”œâ”€â”€ manifest.json     (crawler state)          â”‚
â”‚  â”œâ”€â”€ documents/{doc_id}/                        â”‚
â”‚  â”‚   â”œâ”€â”€ content.md    (extracted text)         â”‚
â”‚  â”‚   â”œâ”€â”€ metadata.json (tags, dates, author)    â”‚
â”‚  â”‚   â”œâ”€â”€ images/       (extracted images)       â”‚
â”‚  â”‚   â”œâ”€â”€ descriptions.json (image descriptions) â”‚
â”‚  â”‚   â””â”€â”€ versions/     (version history)        â”‚
â”‚  â”œâ”€â”€ vectors/chroma.sqlite3                     â”‚
â”‚  â””â”€â”€ graph/knowledge_graph.json                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.3 Configuration Layer

```python
# config/settings.py

@dataclass
class KTSConfig:
    """Central configuration for the KTS system."""
    
    # File share paths to crawl
    source_paths: list[str]
    
    # Supported file extensions
    supported_extensions: list[str] = field(default_factory=lambda: [
        ".docx", ".pdf", ".pptx", ".htm", ".html", ".md", ".txt"
    ])
    
    # Knowledge base root directory
    knowledge_base_path: str = "knowledge_base"
    
    # ChromaDB settings
    chroma_persist_dir: str = "knowledge_base/vectors"
    chroma_collection_text: str = "text_chunks"
    chroma_collection_images: str = "image_descriptions"
    
    # Graph settings
    graph_path: str = "knowledge_base/graph/knowledge_graph.json"
    
    # Chunking settings
    chunk_size: int = 1000       # characters per chunk
    chunk_overlap: int = 200     # overlap between chunks
    
    # Quality gate thresholds (reused from ABS playbook)
    confidence_high: float = 0.90
    confidence_medium: float = 0.66
    
    # Freshness settings
    stale_threshold_days: int = 180  # flag docs older than 6 months
```

---

## 3. Cross-Domain Linking (The Inverted Scope Model)

### 3.1 ABS vs KTS Scoping

```
ABS Waterfall AI                    GSF IR KTS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Deal A â”€â”€â”                          Tool X â”€â”€â”€â”€â”€â”€â”
         â”‚ ISOLATED                               â”œâ”€â”€ Process A â”€â”€â”
Deal B â”€â”€â”˜                          Tool Y â”€â”€â”    â”‚               â”‚
                                             â”œâ”€â”€â”€â”€â”˜               â”‚
Cross-deal = BAD                    Tool Z â”€â”€â”˜                    â”‚
                                                                  â”‚
                                    Doc 1 â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    Doc 2 â—„â”€â”€ spans multiple tools
                                    Doc 3 â—„â”€â”€ and processes
                                    
                                    Cross-domain = THE VALUE
```

### 3.2 How Cross-Linking Works

The knowledge graph enables cross-domain queries:

```python
# "What docs are affected if Tool X changes?"
def get_impact(graph, tool_name: str) -> list[dict]:
    tool_node = find_node(graph, type="tool", name=tool_name)
    
    # Direct: docs that mention this tool
    direct_docs = graph.neighbors(tool_node, edge_type="documented_in")
    
    # Indirect: processes that use this tool â†’ docs about those processes
    processes = graph.neighbors(tool_node, edge_type="uses", reverse=True)
    indirect_docs = []
    for proc in processes:
        indirect_docs.extend(
            graph.neighbors(proc, edge_type="documented_in")
        )
    
    # Training: docs tagged as "training" that cover affected topics
    all_affected = set(direct_docs + indirect_docs)
    training_docs = [d for d in all_affected 
                     if graph.node_attr(d, "doc_type") == "training"]
    
    return {
        "direct_docs": direct_docs,
        "indirect_docs": indirect_docs,
        "training_to_update": training_docs,
    }
```

---

## 4. Multi-Modal Architecture

### 4.1 Image Extraction Pipeline

```python
# Per-format image extraction strategy

EXTRACTION_STRATEGY = {
    ".docx": "python-docx â€” extract embedded images from document.part.rels",
    ".pdf":  "PyMuPDF â€” extract images per page with position metadata",
    ".pptx": "python-pptx â€” extract images from slide shapes",
    ".html": "BeautifulSoup â€” extract <img> tags, download src files",
}
```

### 4.2 Image Manifest Structure

```json
{
  "doc_id": "doc_abc123",
  "images": [
    {
      "image_id": "img_001",
      "filename": "img_001.png",
      "source_page": 5,
      "source_context": "Text immediately surrounding the image...",
      "dimensions": {"width": 800, "height": 600},
      "status": "pending",
      "description": null,
      "described_by": null,
      "described_at": null
    },
    {
      "image_id": "img_002",
      "filename": "img_002.png",
      "source_page": 12,
      "source_context": "Step 3: Click the Settings button...",
      "dimensions": {"width": 1024, "height": 768},
      "status": "described",
      "description": "Screenshot of the Settings dialog in Tool X. The Security tab is selected. The 'Reset Password' button is highlighted in the bottom-right corner. Current user shown as 'jsmith'.",
      "described_by": "maintenance_engineer",
      "described_at": "2026-02-10T14:30:00Z"
    }
  ],
  "summary": {
    "total": 2,
    "pending": 1,
    "described": 1
  }
}
```

### 4.3 Maintenance Engineer Prompt Template

```markdown
# Image Description Template â€” GSF IR KTS

## Instructions
You are describing a screenshot/image extracted from a knowledge document.
Your description will be indexed for search. Be thorough and specific.

## Required Elements
1. **What type of image** â€” screenshot, diagram, flowchart, table, photo
2. **Application/tool shown** â€” name the tool, version if visible
3. **UI elements visible** â€” menus, buttons, tabs, fields, dialogs
4. **Text visible in image** â€” read ALL text: labels, error messages, data values
5. **What action is being shown** â€” what step in a process this represents
6. **Context clues** â€” browser URL, window title, status indicators

## Format
Write 2-5 sentences. Start with the image type, then describe content.

## Example
"Screenshot of the Jenkins CI/CD dashboard showing the 'Production Deploy' 
pipeline. Three stages are visible: Build (green/passed), Test (green/passed), 
and Deploy (yellow/in-progress). The current build number is #1247. The 
sidebar shows 5 previous builds, all green. URL bar shows 
jenkins.internal.gsf.com/job/prod-deploy."
```

---

## 5. Quality Assurance Architecture

### 5.1 Quality Gates (Reused from ABS)

```
Agent Output (Retrieval Service returns context to Copilot)
    â”‚
    â–¼
Quality Gate
    â”‚
    â”œâ”€â”€ confidence â‰¥ 0.90 â”€â”€â–¶ AUTO-ACCEPT, return to Copilot
    â”‚                          Copilot generates confident answer
    â”‚
    â”œâ”€â”€ 0.66 â‰¤ confidence < 0.90 â”€â”€â–¶ ACCEPT WITH CAVEAT
    â”‚                                  Pass caveat to Copilot:
    â”‚                                  "Relevant information found but
    â”‚                                   not fully confident. Consider
    â”‚                                   confirming with: [SME name from graph]"
    â”‚
    â””â”€â”€ confidence < 0.66 â”€â”€â–¶ ESCALATE
                               Pass escalation to Copilot:
                               "Insufficient information to answer
                                reliably. Recommend contacting:
                                [SME name from graph, based on doc authorship]"
```

### 5.2 Citation Requirements

Every retrieval response MUST include:
- Source document name and path (file:// URI for VS Code to open)
- Version number
- Page/section reference
- Last updated date
- If context includes image-described content: note about image location (e.g., "see page 12 for screenshot")

**Note**: Images are NOT returned inline. Citations link to source documents where users can see images in full context.

```python
@dataclass
class Citation:
    doc_id: str
    doc_name: str
    source_path: str              # file:// URI
    version: int
    section: str | None
    page: int | None
    last_updated: str
    image_note: str | None        # "Screenshot on page 12 shows..." (not the image file itself)
```

### 5.3 Freshness Indicators

Every answer includes a freshness badge:

| Badge | Meaning | Criteria |
|-------|---------|----------|
| ğŸŸ¢ CURRENT | Document recently verified | Updated within `stale_threshold_days` |
| ğŸŸ¡ AGING | May be outdated | Between 1x and 2x `stale_threshold_days` |
| ğŸ”´ STALE | Likely outdated | Older than 2x `stale_threshold_days` |
| âšª UNKNOWN | No update date available | Metadata missing |

---

## 6. Security & Access Considerations

| Concern | Approach |
|---------|----------|
| File share permissions | KTS reads files using the service account's permissions â€” same files users can already access |
| No sensitive data reversible from vector store | Embeddings are numerical vectors, not reversible to original text. But chunk text IS stored â€” ensure file shares don't contain restricted content |
| No external API calls for Q&A | GitHub Copilot Chat uses its built-in LLM models. No OpenAI/Anthropic API keys needed for answering questions. |
| Image descriptions via GitHub Models | Human-in-the-loop workflow uses GitHub Models (free via VS Code) â€” no API keys or external services required |
| All processing local/on-premises | ChromaDB is local SQLite. NetworkX is local JSON. Everything runs on-premises. |
| Audit trail | All ingestion actions logged with timestamps, source paths, and operator |

---

## 7. Deployment Model

```
Phase 1: Single-machine deployment
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Developer laptop / shared VM
â”œâ”€â”€ Python virtual environment
â”œâ”€â”€ ChromaDB (local SQLite)
â”œâ”€â”€ NetworkX graph (local JSON)
â”œâ”€â”€ VS Code with KTS Extension installed
â”œâ”€â”€ GitHub Copilot Chat (user interface for Q&A)
â””â”€â”€ CLI for maintenance tasks (crawl, ingest, describe images)

Phase 2 (Future): Shared deployment
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Shared server / VM
â”œâ”€â”€ VS Code Extension points to shared backend
â”œâ”€â”€ Scheduled crawler (cron / Task Scheduler)
â”œâ”€â”€ Persistent storage on network share
â””â”€â”€ Optional: ChromaDB client-server mode

Admin Interface Access:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- Command Palette: KTS: Crawl & Ingest, View Status, Describe Images, etc.
- Image Description Panel: Custom VS Code webview panel for human-in-the-loop vision
- On-demand Status Documents: Markdown reports generated via command
- CLI: Power-user scripts for batch operations
```

---

*Next: See System_Design.md for detailed agent specifications, Data_Model.md for all data structures, and Implementation_Plan.md for the build sequence.*
